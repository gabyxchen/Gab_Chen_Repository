{
  "hash": "c59788103bfed8752fefa05f6d0cd70b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Welcome to CPLN 5920/MUSA 5080\"\nsubtitle: \"Public Policy Analytics\"\nauthor: \"Allison Lassiter\"\ndate: \"January 19, 2026\"\nformat: \n  revealjs:\n    theme: simple\n    slide-number: true\n    chalkboard: true\n    code-line-numbers: true\n    incremental: false\n---\n\n# Today's Agenda\n\n## Part 1: Course Overview\n- **What you'll learn** - concepts\n- **How you'll learn it** - the course structure\n- **The tools we'll use** - software\n\n## Part 2: GitHub & Version Control\n- **Git fundamentals** for data science\n- **GitHub Classroom** workflow\n- **Collaborative coding** practices\n\n## Part 3: Reproducible Research Tools\n- **Quarto** for professional documentation\n- **Markdown** basics for clear communication\n- **RStudio settings** for reproducibility\n\n## Part 4: R Project Workflow\n- **Project organization** best practices\n- **File management** and relative paths\n- **Weekly workflow** you'll follow all semester\n\n## Part 5: Data Analysis with tidyverse\n- **dplyr fundamentals** and function patterns\n- **Pipes** for readable code\n- **group_by() and summarize()** for policy analysis\n\n## Part 6: Hands-On Setup\n- **Portfolio repository** creation\n- **Live demonstration** of complete workflow\n- **Your first analysis** in professional format\n\n---\n\n# Course Overview\n\n## What This Course Is About\n\n- **Advanced spatial analysis** for urban planning and public policy\n- **Data science tools** within policy context\n- **Focus on understanding concepts** rather than just completing code\n- **Professional portfolio development** using modern tools\n\n## Unlike Private Sector Data Science\n\n- Public sector is rarely about optimization\n- **Public goods, governance, equity** considerations\n- **Transparency and interpretability** are crucial\n- **Algorithmic bias** has real consequences for communities\n\n## Course structure\n- Our weekly meetings will be part lecture, part lab\n- You complete: \n  - 5 lab assignments (individual)\n  - Mid-term, final (group projects)\n- Syllabus on Canvas and github\n\n## Assignment weighting\n\n**Problem:** AI tools make it easy to complete code without understanding\n\n**Solution:**\n\n- **35%: 10 weekly in-class quizzes** (test conceptual understanding)\n- **25%: 5 lab assignments** (focus on learning)\n- **GitHub-based workflow** (professional skills)\n\n## The Tools We'll Use\n\n**GitHub:** Industry standard for version control and collaboration\n\n**Quarto:** Modern approach to reproducible research and documentation\n\n**R:** Powerful for spatial analysis and policy-focused statistics\n\n## Professional Development\n\nThese aren't just \"class tools\" - they're **career tools**:\n\n- **Portfolio employers can see**\n- **Version control skills** for any data job\n- **Professional documentation** practices\n\n---\n\n# GitHub Fundamentals\n\n## What is Git?\n\n**Version control system** that tracks changes in files\n\nThink of it as:\n\n- **\"Track changes\" for code projects**\n- **Time machine** for your work\n- **Collaboration tool** for teams\n\n## What is GitHub?\n\n**Cloud hosting** for Git repositories\n\n- **Backup** your work in the cloud  \n- **Share** projects with others\n- **Deploy websites** (like our portfolios)\n- **Collaborate** on code projects\n\n## Key GitHub Concepts\n\n**Repository (repo):** Folder containing your project files\n\n**Commit:** Snapshot of your work at a point in time\n\n**Push:** Send your changes to GitHub cloud\n\n**Pull:** Get latest changes from GitHub cloud\n\n**Clone:** Local copy of your repo\n\n\n## GitHub in This Course\n\n**Your workflow each week:**\n\n```text\n1. Edit files in RStudio\n2. Commit changes with descriptive message  \n3. Push to GitHub\n4. Your portfolio website updates automatically\n```\n\nThis becomes second nature by mid-semester!\n\n\n---\n\n# Quarto Introduction\n\n## What is Quarto?\n\n**Publishing system** that combines:\n\n- Code (R, Python, etc.)\n- Text (explanations, analysis)\n- Output (plots, tables, results)\n\n**Into professional documents**\n\n## Why Quarto?\n\n**Reproducible research:**\n\n- Code and explanation in one place\n- Others can re-run your analysis\n- Professional presentation\n\n**Career relevance:**\n\n- Industry standard for data science communication\n- Creates websites, PDFs, presentations\n- Used at major tech companies and government agencies\n\n## Quarto vs. R Markdown\n\nIf you know R Markdown:\n\n- Quarto is the \"next generation\"\n- Better website creation\n- Works with multiple programming languages\n- Same basic concept, improved features\n\n## Quarto Document Structure\n\nYAML header:\n```yaml\n---\ntitle: \"My Analysis\" \nauthor: \"Your Name\"\ndate: today\nformat: html\n---\n```\n\nR code chunk:\n```r\nlibrary(tidyverse)\ndata <- read_csv(\"data/car_sales_data.csv\")\n```\n\n---\n\n# Markdown Basics\n\n## Text Formatting\n- Markdown is a \"markup language\"\n- You will use this in Quarto and GitHub\n- It is also used in many other places (e.g., Wiki, Notion, Slack) \n\n```markdown\n**Bold text**\n*Italic text*\n***Bold and italic***\n`code text`\n~~Strikethrough~~\n```\n\n**Bold text**  \n*Italic text*  \n***Bold and italic***  \n`code text`  \n~~Strikethrough~~\n\n## Headers\n\n```markdown\n# Main Header\n## Section Header  \n### Subsection Header\n```\n\nUse headers to organize your analysis sections.\n\n## Lists\n\n```markdown\n## Unordered List\n- Item 1\n- Item 2\n  - Sub-item A\n  - Sub-item B\n\n## Ordered List  \n1. First item\n2. Second item\n3. Third item\n```\n\n## Links and Images\n\n```markdown\n[Link text](https://example.com)\n[Link to another page](about.qmd)\n![Alt text](path/to/image.png)\n```\n\nEssential for professional portfolios:\n\n- Link to data sources\n- Reference course materials  \n- Include relevant images/plots\n\n---\n\n# R recap\n\n## Why R for Policy Analysis?\n\n- **Free and open source**\n- **Excellent for spatial data** \n- **Strong statistical capabilities**\n- **Large community** in urban planning/policy\n- **Reproducible research** workflows\n\n\n\n---\n\n# R Project Workflow\n\n## RStudio Projects: Essential Habit\n\n**Always work within projects** for:\n\n- **Organized file structure** - data, scripts, outputs in one place\n- **Relative file paths** - `\"data/cars.csv\"` works for everyone  \n- **Version control integration** - Git works seamlessly\n- **Reproducible workflow** - others can run your code\n\n**Professional standard** - employers expect this!\n\n## Project Benefits for This Course\n\n```r\n# This works reliably in projects:\ncar_data <- read_csv(\"data/car_sales_data.csv\")\n\n# This breaks when shared:\ncar_data <- read_csv(\"/Users/yourname/Desktop/cars.csv\")\n```\n\n**We'll work in projects all semester** - builds good habits!\n\n\n## Creating Your Project\n\n**Step 1: Clone your GitHub repository**\n- You can clone in GitHub desktop or through the terminal in RStudio\n- GitHub desktop is easier at first, but terminal is faster once you learn how\n\n```bash\ngit clone https://github.com/username/cpln5920-portfolio.git\ncd cpln5920-portfolio\n```\n\n**Step 2: Open in RStudio**\n\n- Open RStudio\n- File → Open Project\n- Navigate to your cloned folder\n- Select the `.Rproj` file\n\n## Project File Structure\n\n**Organized structure from day one:**\n\n```text\ncpln5920-portfolio/\n├── .Rproj\n├── .gitignore\n├── data/\n│   ├── raw/\n│   └── processed/\n├── scripts/\n├── docs/\n├── outputs/\n│   ├── figures/\n│   └── tables/\n└── week01/\n    ├── index.qmd\n    └── data/\n```\n\n## Why This Structure Matters\n\n**Professional habit:**\n\n- **Anyone can understand** your project layout\n- **Scripts know where to find** data files\n- **Easy to maintain** as projects grow\n- **Industry standard** for data science teams\n\n\n## File Naming Conventions\n\n**Be consistent and descriptive:**\n\n```text\n# Good examples:\nweek01_exploratory_analysis.qmd\n2025-09-08_census_data_cleaning.R\nphiladelphia_housing_2020-2024.csv\n\n# Avoid these:\nanalysis.qmd\ntemp.R\ndata.csv\nnew_version_final.qmd\nnew_version_final2_final_final.qmd\n\n```\n\n## Working with Data Files\n\n**Best practices for this course:**\n\n```r\n# Raw data (never edit these!)\nraw_census <- read_csv(here(\"data\", \"raw\", \"acs_2022_philadelphia.csv\"))\n\n# Process and save cleaned versions\nclean_census <- raw_census %>%\n  clean_names() %>%\n  filter(!is.na(median_income))\n\nwrite_csv(clean_census, here(\"data\", \"processed\", \"acs_2022_clean.csv\"))\n\n# Use processed data in analysis\nanalysis_data <- read_csv(here(\"data\", \"processed\", \"acs_2022_clean.csv\"))\n```\n\n## RStudio Settings for Reproducibility\n\n**Critical settings to change RIGHT NOW:**\n\n**Tools → Global Options → General:**\n\n- **Uncheck** \"Restore most recently opened project at startup\"\n- **Uncheck** \"Restore previously opened source documents\"\n\n**Tools → Global Options → Workspace:**\n\n- **Uncheck** \"Restore .RData into workspace at startup\"  \n- **Set** \"Save workspace to .RData on exit\" to **\"Never\"**\n\n## Why These Settings Matter\n\n**Without these changes:**\n\n- Old objects stick around between sessions\n- Code appears to work but fails for others\n- Hidden dependencies break reproducibility\n- **Your portfolio assignments might not run for TAs!**\n\n**With these settings:**\n\n- Fresh environment every time\n- Code must be complete and self-contained\n- True reproducibility\n- Professional habits from day one\n\n## Managing R Environment\n\n**Keep your environment clean:**\n\n```r\n# Start each session fresh\nrm(list = ls())\n\n# Use projects instead of setwd()\n# NEVER use setwd() in your code!\n\n# Check your working directory\ngetwd()  # Should be your project root\n\n# Use here() for all file paths\nhere(\"data\", \"my_file.csv\")\n```\n\n---\n\n# tidyverse Philosophy\n\n**Collection of packages** designed for data science:\n\n- **Consistent syntax** across functions\n- **Readable code** that tells a story\n- **Efficient workflows** for common tasks\n\n## Tibbles vs Data Frames\n\n**Tidyverse uses \"tibbles\"** - enhanced data frames:\n\n```r\n# Traditional data frame\nclass(data)\n# [1] \"data.frame\"\n\n# Convert to tibble  \ncar_data <- as_tibble(data)\nclass(car_data)\n# [1] \"tbl_df\" \"tbl\" \"data.frame\"\n```\n\n## Why Tibbles Are Better\n\n**Smarter printing:**\n\n- Shows first 10 rows by default\n- Displays column types\n- Fits nicely on screen\n\n**We'll see the difference with our car data...**\n\n## Essential dplyr Functions\n\nWe'll use these constantly:\n\n- `select()` - choose columns\n- `filter()` - choose rows  \n- `mutate()` - create new variables\n- `summarize()` - calculate statistics\n- `group_by()` - operate on groups\n\n## dplyr Function Rules\n\n**All dplyr functions follow the same pattern:**\n\n1. **First argument is always a data frame**\n2. **Subsequent arguments describe which columns to operate on** (using variable names without quotes)\n3. **Output is always a new data frame**\n\nThis consistency makes dplyr predictable and easy to learn!\n\n## Function Pattern Examples\n\n```r\n# Rule 1: Data frame first\nselect(car_data, Manufacturer, Price)\nfilter(car_data, Price > 20000)\nmutate(car_data, price_k = Price / 1000)\n\n# Rule 2: Column names without quotes\nselect(car_data, Manufacturer, Model, Price)  # Not \"Manufacturer\"\nfilter(car_data, Year >= 2020, Mileage < 50000)\n\n# Rule 3: Always returns a new data frame\nnew_data <- select(car_data, Manufacturer, Price)\n# car_data is unchanged, new_data contains selected columns\n```\n\n## Live Demo: Basic dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Load car sales data\ncar_data <- read_csv(\"data/car_sales_data.csv\")\n\n# Basic exploration\nglimpse(car_data)\nnames(car_data)\n```\n:::\n\n\n## Data Manipulation Pipeline\n\n**Pipes (`%>%`) are the magic of dplyr:**\n\n```r\n# The power of pipes - read as \"then\"\ncar_summary <- data %>%\n  filter(`Year of manufacture` >= 2020) %>%      # Recent models only\n  select(Manufacturer, Model, Price, Mileage) %>% # Key variables\n  mutate(price_k = Price / 1000) %>%             # Convert to thousands\n  filter(Mileage < 50000) %>%                    # Low mileage cars\n  group_by(Manufacturer) %>%                     # Group by brand\n  summarize(                                     # Calculate statistics\n    avg_price = mean(price_k, na.rm = TRUE),\n    count = n()\n  )\n```\n\n## Understanding Pipes\n\n**What is `%>%`?**\n\n- Takes the output from the left side\n- Feeds it as the **first argument** to the function on the right side\n- Think: \"and then...\"\n\n**Without pipes (nested functions):**\n```r\n# Hard to read - inside out!\ncar_summary <- summarize(\n  group_by(\n    filter(\n      mutate(\n        select(filter(data, `Year of manufacture` >= 2020), \n               Manufacturer, Model, Price, Mileage),\n        price_k = Price / 1000),\n      Mileage < 50000),\n    Manufacturer),\n  avg_price = mean(price_k, na.rm = TRUE),\n  count = n()\n)\n```\n\n## Without Pipes (Multiple Objects)\n\n**Alternative: create many intermediate objects**\n```r\n# Clutters your environment\nrecent_cars <- filter(data, `Year of manufacture` >= 2020)\nkey_vars <- select(recent_cars, Manufacturer, Model, Price, Mileage)\nprice_thousands <- mutate(key_vars, price_k = Price / 1000)\nlow_mileage <- filter(price_thousands, Mileage < 50000)\ngrouped_cars <- group_by(low_mileage, Manufacturer)\ncar_summary <- summarize(grouped_cars, \n                        avg_price = mean(price_k, na.rm = TRUE),\n                        count = n())\n```\n\n**Problems:** Lots of temporary objects, hard to follow the logic\n\n## Why Pipes Are Better\n\n**Readable:** Follow the logical flow of analysis\n\n**Efficient:** No temporary objects cluttering environment\n\n**Debuggable:** Easy to run line-by-line\n\n**Professional:** Industry standard for data science\n\n## Reading Pipes Aloud\n\n```r\ncar_data %>%\n  filter(Price > 15000) %>%\n  select(Manufacturer, Price) %>%\n  group_by(Manufacturer) %>%\n  summarize(avg_price = mean(Price))\n```\n\n**Read as:**\n\n\"Take car_data, **then** filter for cars over $15,000, **then** select manufacturer and price columns, **then** group by manufacturer, **then** calculate average price\"\n\n## Understanding group_by() and summarize()\n\n**These functions work as a team:**\n\n- `group_by()` - **sets up grouping** for subsequent operations\n- `summarize()` - **collapses rows** into summary statistics\n\n## How group_by() Works\n\n```r\n# group_by() doesn't change what you see...\ncar_data %>% \n  group_by(Manufacturer)\n\n# ...but it sets up invisible grouping for next operations\n# Look for: \"Groups: Manufacturer [5]\" in the output\n```\n\n**Key insight:** `group_by()` **prepares** the data, doesn't transform it yet\n\n## How summarize() Works\n\n```r\n# Without grouping - one row of results\ncar_data %>%\n  summarize(\n    avg_price = mean(Price, na.rm = TRUE),\n    total_cars = n()\n  )\n# Result: 1 row with overall averages\n\n# With grouping - one row per group\ncar_data %>%\n  group_by(Manufacturer) %>%\n  summarize(\n    avg_price = mean(Price, na.rm = TRUE),\n    total_cars = n()\n  )\n# Result: 5 rows (one per manufacturer)\n```\n\n## Before and After Example\n\n**Original data (imagine this):**\n```\nManufacturer  Price   Mileage\nToyota       25000    30000\nToyota       28000    15000  \nHonda        22000    45000\nHonda        30000    20000\nFord         35000    10000\n```\n\n**After group_by(Manufacturer) %>% summarize(...):**\n```\nManufacturer  avg_price  total_cars\nToyota       26500      2\nHonda        26000      2  \nFord         35000      1\n```\n\n## Common summarize() Functions\n\n**Essential summary functions:**\n```r\ncar_data %>%\n  group_by(Manufacturer) %>%\n  summarize(\n    count = n(),                          # Number of rows\n    avg_price = mean(Price, na.rm = TRUE), # Average\n    med_price = median(Price, na.rm = TRUE), # Median  \n    min_price = min(Price, na.rm = TRUE),   # Minimum\n    max_price = max(Price, na.rm = TRUE),   # Maximum\n    std_dev = sd(Price, na.rm = TRUE)       # Standard deviation\n  )\n```\n\n## Policy Analysis Applications\n\n**Perfect for policy questions like:**\n\n- Average household income **by neighborhood**\n- Crime rates **by police district**  \n- Housing prices **by year**\n- Transportation usage **by demographic group**\n- Educational outcomes **by school district**\n\n**Pattern:** `group_by(category) %>% summarize(metric)`\n\n---\n\n# Recap on Course Structure\n\n## Weekly Pattern\n\n**Tuesday Class:**\n- New concepts and methods\n- Hands-on coding practice\n- Lab work with TA support\n\n**During Week:**\n- Complete portfolio assignments\n- Weekly notes and reflection\n- Office hours for help\n\n## Assessment Philosophy\n\n**Focus on understanding, not perfect code:**\n\n- **Weekly quizzes** test concepts\n- **Low stakes labs** encourage experimentation\n- **Professional development** throughout\n\n## Portfolio Development\n\n**Your GitHub portfolio will include:**\n\n- Completed lab analyses\n- Professional documentation\n- Work you can show employers\n\n---\n\n# Getting Started Today\n\n## Portfolio Setup Process\n\n1. **Accept GitHub Classroom assignment**\n2. **Clone repository to your computer**  \n3. **Customize with your information**\n4. **Enable GitHub Pages**\n5. **Complete first analysis**\n\n## What We'll Accomplish\n\nBy end of today:\n\n- **Working portfolio repository**\n- **Live website** with your work\n- **First R analysis** in professional format\n- **Familiarity with workflow**\n\n## Support Available\n\n- **Allison and Zhanchao** circulating during hands-on time\n- **Office hours** starting this week\n- **Canvas discussion** for course questions\n\n---\n\n# Questions?\n\n## Ready to Get Started?\n\n**Next:** Portfolio setup + Lab 0\n\n**Remember:** This is a learning process - ask for help when you need it!\n\n---\n\n# Live Demo: Portfolio Setup\n\n*[Switch to live demonstration of GitHub workflow]*",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}